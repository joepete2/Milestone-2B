{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [29:56<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "k-neighbors \t \t \t 98.07142857142885\n",
      "Logistic Regression \t \t 94.10952380952453\n",
      "Linear Discriminate Analysis \t 92.1000000000009\n",
      "Decision Tree Classifier \t 77.43333333333365\n",
      "Bagging Classifier \t \t 88.38571428571514\n",
      "Random Forest \t \t \t 94.34285714285787\n",
      "Boosting \t \t \t 79.88571428571471\n",
      "Support Vector Machine \t \t 97.12857142857187\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2276,    0,   90,    0,    0,    0,    1,   20,    0,    0],\n",
       "       [   0, 2088,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0, 2187,    0,    0,    0,    0,    0,    0,    0],\n",
       "       [   0,    0,    0, 2093,    0,   93,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,   99, 2002,   20,   80,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    2, 2142,    0,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0, 1801,    0,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0, 1827,    0,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0, 2140,    0],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0, 2039]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Spencer Baker\n",
    "Date: 5/24/2021\n",
    "Notes: Different classification algorithms for Milestone 2B\n",
    "    Inputs - change of impedance\n",
    "    Output - Exercise classification\n",
    "    Algorithms - \n",
    "        K-Nearest Neighbor\n",
    "        Logistic Regression\n",
    "        Linear Discriminate Analysis\n",
    "        Quadratic Discriminate Analysis\n",
    "        Bagging\n",
    "        Random Forests\n",
    "        Boosting\n",
    "        Suport Vector Machines\n",
    "\"\"\"\n",
    "\n",
    "# --- INITIALIZE --- #\n",
    "# clear console\n",
    "\n",
    "\n",
    "# import tools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# import models\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# import evaluations\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# import scipy\n",
    "# import matplotlib.pyplot as plt\n",
    "# import urllib\n",
    "# import joblib\n",
    "# from pylab import rcParams\n",
    "\n",
    "\n",
    "\n",
    "# --- LOAD DATA --- #\n",
    "# data = pd.read_csv('2B_Range_Data.csv')\n",
    "# data = pd.read_csv('2B_Peak_Valley_Data.csv')\n",
    "# data = pd.read_csv('featuresCadaver2.all.csv')\n",
    "# data = pd.read_csv('featuresCadaver2.filtered.all.csv')\n",
    "data = pd.read_csv('featuresCadaver2.filtered.maxmin.all.csv')\n",
    "# data = pd.read_csv('featuresCadaver2.unfiltered.maxmin.all.csv')\n",
    "X = data.drop(columns = 'value')\n",
    "y = data['value']\n",
    "\n",
    "\n",
    "# --- ALGORITHMS AND EVALUATION --- #\n",
    "# number of iterations\n",
    "N = 1000  #1000\n",
    "\n",
    "# scores\n",
    "k_neighbor_score = 0\n",
    "LR_ovo_score = 0\n",
    "LDA_score = 0\n",
    "QDA_score = 0\n",
    "tree_score = 0\n",
    "Bag_score = 0\n",
    "RF_score = 0\n",
    "Boost_score = 0\n",
    "SV_score = 0\n",
    "\n",
    "#initialize confusion matrix vectors\n",
    "totalPredictionsKNN = []\n",
    "totalPredictionsLR = []\n",
    "totalPredictionsLDA = []\n",
    "totalPredictionsTree = []\n",
    "totalPredictionsBag = []\n",
    "totalPredictionsRF = []\n",
    "totalPredictionsBoost = []\n",
    "totalPredictionsSV = []\n",
    "totalTest = []\n",
    "\n",
    "\n",
    "\n",
    "for i in tqdm(range(N)): # for i in range(0,N):\n",
    "    \n",
    "    # Randomly split training, testing data\n",
    "    [X_train, X_test, y_train, y_test] = train_test_split(X, y, test_size=0.3)\n",
    "    \n",
    "    \n",
    "    # K-Nearest Neighbor\n",
    "    k = 1\n",
    "    KNN_algorithm = KNeighborsClassifier(n_neighbors=k)\n",
    "    KNN_algorithm.fit(X_train, y_train)\n",
    "    KNN_yhat = KNN_algorithm.predict(X_test)\n",
    "    k_neighbor_score += accuracy_score(y_test, KNN_yhat)\n",
    "    totalPredictionsKNN = np.concatenate((totalPredictionsKNN, KNN_yhat))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Logistic Regression (one versus one or one versus all?)\n",
    "    LR_ovo_algorithm = LogisticRegression(max_iter = 100000)    # 'multi_class',‘auto’, ‘ovr’, ‘multinomial’})\n",
    "    LR_ovo_algorithm.fit(X_train, y_train)\n",
    "    LR_ovo_yhat = LR_ovo_algorithm.predict(X_test)\n",
    "    LR_ovo_score += accuracy_score(y_test, LR_ovo_yhat)\n",
    "    totalPredictionsLR = np.concatenate((totalPredictionsLR, LR_ovo_yhat))\n",
    "    \n",
    "    # Linear Discriminate Analysis\n",
    "    LDA_algorithm = LinearDiscriminantAnalysis()\n",
    "    LDA_algorithm.fit(X_train, y_train)\n",
    "    LDA_yhat = LDA_algorithm.predict(X_test)\n",
    "    LDA_score += accuracy_score(y_test, LDA_yhat)\n",
    "    totalPredictionsLDA = np.concatenate((totalPredictionsLDA, LDA_yhat))\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    # Quadratic Discriminate Analysis\n",
    "    QDA_algorithm = QuadraticDiscriminantAnalysis()\n",
    "    QDA_algorithm.fit(X_train, y_train)\n",
    "    QDA_yhat = QDA_algorithm.predict(X_test)\n",
    "    QDA_score += accuracy_score(y_test, QDA_yhat)\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    # Trees\n",
    "    tree_algorithm = DecisionTreeClassifier()\n",
    "    tree_algorithm.fit(X_train, y_train)\n",
    "    tree_yhat = tree_algorithm.predict(X_test)\n",
    "    tree_score += accuracy_score(y_test, tree_yhat)\n",
    "    totalPredictionsTree = np.concatenate((totalPredictionsTree, tree_yhat))\n",
    "    \n",
    "\n",
    "    # Bagging\n",
    "    Bag_algorithm = BaggingClassifier()\n",
    "    Bag_algorithm.fit(X_train, y_train)\n",
    "    Bag_yhat = Bag_algorithm.predict(X_test)\n",
    "    Bag_score += accuracy_score(y_test, Bag_yhat)\n",
    "    totalPredictionsBag = np.concatenate((totalPredictionsBag, Bag_yhat))\n",
    "    \n",
    "    \n",
    "    # Random Forests\n",
    "    RF_algorithm = RandomForestClassifier()\n",
    "    RF_algorithm.fit(X_train, y_train)\n",
    "    RF_yhat = RF_algorithm.predict(X_test)\n",
    "    RF_score += accuracy_score(y_test, RF_yhat)\n",
    "    totalPredictionsRF = np.concatenate((totalPredictionsRF, RF_yhat))\n",
    "    \n",
    "    \n",
    "    # Boosting\n",
    "    # B = 1\n",
    "    min_samples = 10\n",
    "    # d = 1\n",
    "    L = 1e-1\n",
    "    Boost_algorithm = GradientBoostingClassifier(learning_rate=L, min_samples_split=min_samples)\n",
    "    Boost_algorithm.fit(X_train, y_train)\n",
    "    Boost_yhat = Boost_algorithm.predict(X_test)\n",
    "    Boost_score += accuracy_score(y_test, Boost_yhat)\n",
    "    totalPredictionsBoost = np.concatenate((totalPredictionsBoost, Boost_yhat))\n",
    "    \n",
    "    \n",
    "    # Support Vector Machines\n",
    "    SV_algorithm = SVC(C=250)\n",
    "    SV_algorithm.fit(X_train, y_train)\n",
    "    SV_yhat = SV_algorithm.predict(X_test)\n",
    "    SV_score += accuracy_score(y_test, SV_yhat)\n",
    "    totalPredictionsSV = np.concatenate((totalPredictionsSV, SV_yhat))\n",
    "    \n",
    "    \n",
    "    totalTest = np.concatenate((totalTest,y_test))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "# --- EVALUATION --- #\n",
    "# scores\n",
    "print('\\n')\n",
    "print('k-neighbors', '\\t', '\\t', '\\t', 100*k_neighbor_score/N)\n",
    "print('Logistic Regression', '\\t', '\\t', 100*LR_ovo_score/N)\n",
    "print('Linear Discriminate Analysis', '\\t', 100*LDA_score/N)\n",
    "# print('Quadratic Discriminate Analysis', '\\t', 100*QDA_score/N)\n",
    "print('Decision Tree Classifier', '\\t', 100*tree_score/N)\n",
    "print('Bagging Classifier', '\\t', '\\t', 100*Bag_score/N)\n",
    "print('Random Forest', '\\t', '\\t', '\\t', 100*RF_score/N)\n",
    "print('Boosting', '\\t', '\\t', '\\t', 100*Boost_score/N)\n",
    "print('Support Vector Machine', '\\t', '\\t', 100*SV_score/N)\n",
    "\n",
    "\n",
    "\n",
    "# confusion matrix\n",
    "KNN = confusion_matrix(totalTest, totalPredictionsKNN)\n",
    "np.savetxt('confusionKNN5.csv', KNN , delimiter=',')\n",
    "LR = confusion_matrix(totalTest, totalPredictionsLR)\n",
    "np.savetxt('confusionLR5.csv', LR , delimiter=',')\n",
    "LDA = confusion_matrix(totalTest, totalPredictionsLDA)\n",
    "np.savetxt('confusionLDA5.csv', LDA , delimiter=',')\n",
    "Tree = confusion_matrix(totalTest, totalPredictionsTree)\n",
    "np.savetxt('confusionTree5.csv', Tree , delimiter=',')\n",
    "Bag = confusion_matrix(totalTest, totalPredictionsBag)\n",
    "np.savetxt('confusionBag5.csv', Bag , delimiter=',')\n",
    "RF = confusion_matrix(totalTest, totalPredictionsRF)\n",
    "np.savetxt('confusionRF5.csv', RF , delimiter=',')\n",
    "Boost = confusion_matrix(totalTest, totalPredictionsBoost)\n",
    "np.savetxt('confusionBoost5.csv', Boost , delimiter=',')\n",
    "SV = confusion_matrix(totalTest, totalPredictionsSV)\n",
    "np.savetxt('confusionSV5.csv', SV , delimiter=',')\n",
    "KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
